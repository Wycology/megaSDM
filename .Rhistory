limit = 999,
fields = c('species',
'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
start = 699,
limit = 999,
fields = c('species',
'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
start = 899,
limit = 999,
fields = c('species',
'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
start = 998,
limit = 999,
fields = c('species',
'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
start = 998,
fields = c('species',
'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
start = 996,
limit = 998,
fields = c('species',
'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
limit = 99999,
#                          fields = c('species',
#                                     'decimalLatitude',
#                                     'decimalLongitude', 'basisOfRecord',
#                                     'issues','locality', 'elevation',
#                                     'elevationAccuracy', 'continent',
#                                     'stateProvince', 'county',
#                                     'year', 'month', 'day', 'evenDate',
#                                     'references', 'license', 'geodeticDatum',
#                                     'gbifID', 'type', 'preparations',
#                                     'catalogNumber', 'occurrenceStatus'))$data
# # Got rid of 'infraspecificEpithet' because it only exists for subspecies
if(is.null(Occ)) {
message("No occurrences found within study area! Check species name or study area extent")
FailedSpecies <- c(FailedSpecies, s)
next()
}
OurSpp$OrigOccurrences[i] <- nrow(Occ)
} else {
print(paste("Subspecies ", i, " of ", nspp, ": ", s, sep = ""))
print(paste0("   Beginning search: ", Sys.time()))
OurSpp$OrigOccurrences[i] <- 0
OurSpp$Occurrences[i] <- 0
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
limit = 99999,
fields = c('species',
'infraspecificEpithet', 'decimalLatitude',
'decimalLongitude', 'basisOfRecord',
'issues','locality', 'elevation',
'elevationAccuracy', 'continent',
'stateProvince', 'county',
'year', 'month', 'day', 'evenDate',
'references', 'license', 'geodeticDatum',
'gbifID', 'type', 'preparations',
'catalogNumber', 'occurrenceStatus'))$data
if(is.null(Occ)) {
message("No occurrences found within study area! Check species name or study area extent")
FailedSpecies <- c(FailedSpecies, s)
next()
}
#Adds subspecies name to the species column and deletes subspecies column
Occ$species <- paste0(Occ$species, " ", Occ$infraspecificEpithet)
OurSpp$OrigOccurrences[i] <- nrow(Occ)
}
#Print progress to console
print(paste0("   Finishing search: ", Sys.time()))
print(paste0("   Number original occurrences: ", nrow(Occ)))
if(nrow(Occ) == 0) {
print(paste0("   Species failed, no search data found: ", s))
} else if (!is.atomic(Occ)) {
#Removes fossils
Occ <- Occ[!Occ$basisOfRecord == "FOSSIL_SPECIMEN", ]
#Removes geographical issues with the data
Occ <- Occ[!grepl("cdiv",  Occ$issues), ]
Occ <- Occ[!grepl("cdout",  Occ$issues), ]
Occ <- Occ[!grepl("cdrepf",  Occ$issues), ]
Occ <- Occ[!grepl("cdreps",  Occ$issues), ]
Occ <- Occ[!grepl("gdativ",  Occ$issues), ]
Occ <- Occ[!grepl("preneglat",  Occ$issues), ]
Occ <- Occ[!grepl("preneglon",  Occ$issues), ]
Occ <- Occ[!grepl("preswcd",  Occ$issues), ]
Occ <- Occ[!grepl("txmatnon",  Occ$issues), ]
Occ <- Occ[!grepl("zerocd",  Occ$issues), ]
#Removes duplicates, log those removed
Occ <- Occ[!duplicated(data.frame(Occ$decimalLatitude, Occ$decimalLongitude)), ]
OurSpp$Occurrences[i] <- nrow(Occ)
if (exists("studyLongitude")) {
#clips the occurrences to the study area, logs species counts
SA_Occ <- Occ[as.numeric(Occ$decimalLongitude) >= studyLongitude[1], ]
SA_Occ <- SA_Occ[as.numeric(SA_Occ$decimalLongitude) <= studyLongitude[2], ]
SA_Occ <- SA_Occ[as.numeric(SA_Occ$decimalLatitude) >= studyLatitude[1], ]
SA_Occ <- SA_Occ[as.numeric(SA_Occ$decimalLatitude) <= studyLatitude[2], ]
OurSpp$StudyArea_Occur[i] <- nrow(SA_Occ)
print(paste0("   Number in the study area: ", nrow(SA_Occ)))
} else {
OurSpp$StudyArea_Occur[i] <- NA
}
OurSpp$SpeciesSearched[i] <- s
#Records details about species as found by GBIF
sppkeys <- OurSpp$Keys[i]
specurl <- paste("http://api.gbif.org/v1/species/", trimws(sppkeys[1]), sep="")
URLRead <- colnames(read.csv(specurl))
gbifapidata <- gsub("\\.", "_", URLRead)
OurSpp$Species[i] <- paste(as.character(substr(gbifapidata[grep("^species_", gbifapidata)], 9, nchar(gbifapidata[grep("^species_", gbifapidata)]))))
if (length(grep("^class_", gbifapidata)) > 0) {
OurSpp$Class[i] <- paste(as.character(substr(gbifapidata[grep("^class_", gbifapidata)], 7, nchar(gbifapidata[grep("^class_", gbifapidata)]) - 1)))
}
if (length(grep("^family_", gbifapidata)) > 0) {
OurSpp$Family[i] <- paste(as.character(substr(gbifapidata[grep("^family_", gbifapidata)], 8, nchar(gbifapidata[grep("^family_", gbifapidata)]))))
}
if (length(grep("^genus_", gbifapidata)) > 0) {
OurSpp$Genus[i] <- paste(as.character(substr(gbifapidata[grep("^genus_", gbifapidata)], 7, nchar(gbifapidata[grep("^genus_", gbifapidata)]))))
}
#Writes occurrences
setwd(output)
#Uses species name from our SppList file as occurrence file name for the csv
write.csv(Occ, file = paste(gsub(" ", "_", s), ".csv", sep = ""), row.names = FALSE)
print(paste0("   Finishing species: ", Sys.time()))
} else {
print(paste0("   Species failed, no search data found: ", s))
}
OurSpp <<- OurSpp
FailedSpecies <<- FailedSpecies
rm(Occ)
gc()
}
}
#It is looped to avoid timeout or temporary internet connectivity issues
speciterate(1, nspp)
if (exists("p")) {
while (p < nspp) {
speciterate(p, nspp)
}
}
#Adds species with 0 occurrences to failed species
FailedSpecies <- unique(c(FailedSpecies, OurSpp$Scientific.Name[which(OurSpp$OrigOccurrences == 0)]))
#Write "FailedSpecies" csv
if (length(FailedSpecies) > 0) {
message(paste0("Species Generated in Failed Species List: Check ", paste0(output, "/", "FailedSpecies.csv"), " for failed species"))
write.csv(FailedSpecies, paste0(output, "/", "FailedSpecies.csv"), row.names = FALSE)
}
OurSpp$OrigOccurrences <- as.numeric(OurSpp$OrigOccurrences)
OurSpp$Occurrences <- as.numeric(OurSpp$Occurrences)
OurSpp$StudyArea_Occur <- as.numeric(OurSpp$StudyArea_Occur)
if (!dir.exists(paste0(output, "/SpeciesCounts"))) {
dir.create(paste0(output, "/SpeciesCounts"))
}
write.csv(OurSpp, paste0(output, "/SpeciesCounts/SpeciesCounts.csv"), row.names = FALSE)
return(OurSpp)
}
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
limit = 99999
#                          fields = c('species',
#                                     'decimalLatitude',
#                                     'decimalLongitude', 'basisOfRecord',
#                                     'issues','locality', 'elevation',
#                                     'elevationAccuracy', 'continent',
#                                     'stateProvince', 'county',
#                                     'year', 'month', 'day', 'evenDate',
#                                     'references', 'license', 'geodeticDatum',
#                                     'gbifID', 'type', 'preparations',
#                                     'catalogNumber', 'occurrenceStatus')
)$data
OurSpp$Keys
occ_search(taxonKey=OurSpp$Keys[i])
occ_search(taxonKey=OurSpp$Keys[i], limit = 9999)
install.packages("rgbif")
spplist
#Searches for occurrences points given the species keys
Occ <- rgbif::occ_search(taxonKey = OurSpp$Keys[i],
decimalLatitude = paste(decimalLatitude, collapse = ","),
decimalLongitude = paste(decimalLongitude, collapse = ","),
hasCoordinate = TRUE,
limit = 99999
#                          fields = c('species',
#                                     'decimalLatitude',
#                                     'decimalLongitude', 'basisOfRecord',
#                                     'issues','locality', 'elevation',
#                                     'elevationAccuracy', 'continent',
#                                     'stateProvince', 'county',
#                                     'year', 'month', 'day', 'evenDate',
#                                     'references', 'license', 'geodeticDatum',
#                                     'gbifID', 'type', 'preparations',
#                                     'catalogNumber', 'occurrenceStatus')
)$data
Pollen_Data <- read.csv(file.choose())
Pollen_Data_Sub <- Pollen_Data[which(Pollen_Data$Island == 0), ]
Pollen_Data_Sub <- Pollen_Data_Sub[-grep("Ocean", Pollen_Data_Sub$Notes), ]
#Function to bin and spatially filter the points (adapted from Varela subsampling)
#DF is the data frame
#resolution is the resolution of the filter (bin widths) in the crs of the data
SpatialSample <- function (DF, resolution) {
names(DF)[c(grep("lon", tolower(names(DF))),
grep("^x$", tolower(names(DF))))] <- "Longitude"
names(DF)[c(grep("lat", tolower(names(DF))),
grep("^y$", tolower(names(DF))))] <- "Latitude"
EnvOccur <- data.frame(CoreID = DF$CoreID, Longitude = DF$Longitude, Latitude = DF$Latitude)
EnvOccur <- EnvOccur[complete.cases(EnvOccur),]
#cycle through all of the environmental variables (columns 3 to end)
nsamples <- c()
out_ptz <- data.frame(CoreID = EnvOccur[, 1])
for(i in 2:length(names(EnvOccur))) {
#make a data frame that is this variable with no NA values
k <- EnvOccur[!is.na(EnvOccur[, i]), i]
#calculate the observed range of this variable
rg <- range(k)
#figure out the resolution from the number of bins
res <- resolution
#rescale the axis by the range and bin size, so the value is just a
#number from 1 to no_bins for its bin membership
d <- (EnvOccur[, i] - rg[1]) / res
#d is now a vector of values ranging from 0 to no_bins
f <- as.numeric(ceiling(d))
#f is a vector of bin membership
f[f == 0] <- 1 #move the zeros into the 1 bin
#correct the name of the vector, so it will carry over to the output
names(f) <- names(EnvOccur)[i]
#add the bin membership vector to the output df for this section
out_ptz <- cbind(out_ptz, f)
#get the names correct
names(out_ptz)[length(names(out_ptz))] <- names(EnvOccur)[i]
}
#subsample the bin membership df to come up with the filled bins
sub_ptz <- dplyr::distinct(out_ptz[,-1])
#count the number of filled bins
no_grps <- nrow(sub_ptz)
#add a column with the group membership number; this number is arbitrary
sub_ptz$grp <- c(1:no_grps)
#join the out_ptz with the subsample to capture the group membership info
#note: join() will automatically match the variable names from these two dfs
out_ptz <- suppressMessages(dplyr::left_join(out_ptz, sub_ptz))
#out_ptz now has a group membership  for each input point
#make a landing spot for the data
final_out <- data.frame(CoreID = c(), x = numeric(), y = numeric())
#cycle through each group
for(i in 1:no_grps) {
#subset to the members of the ith group, keep only the Latitude and Longitude
grp_mbrs <- out_ptz[out_ptz$grp == i, ]
#pick one of these group members to output
grp_out <- grp_mbrs[sample(1:nrow(grp_mbrs), 1), ]
#bind this sampled row to the output df
final_out <- rbind(final_out, grp_out)
}
#return the subsampled points as a df of Latitude and Longitude values
final_out <- data.frame(CoreID = final_out[, 1])
final_out <- merge(final_out, EnvOccur, by = "CoreID", all.x = TRUE)
return(final_out)
}
PollenSub <- SpatialSample(Pollen_Data_Sub, 1)
PollenSub <- merge(PollenSub, Pollen_Data_Sub, by = c("CoreID", "Latitude", "Longitude"), all.x = TRUE)
#To do interactions terms, we need to center the variables
#If any variables need log-transformation, do that before centering
LogVar <- c("CoreLength",
"MedianResidence",
"RangeElev",
"MeanSlope",
"BasinArea_sqkm",
"RangeW",
"PE_Median",
"RangeW_Corr")
for(i in 1:length(LogVar)) {
FocusCol <- grep(LogVar[i], names(PollenSub))
PollenSub[, FocusCol] <- log(PollenSub[, FocusCol])
}
ScaleVar <- c("CoreLength",
"MedianResidence",
"LongestTime",
"NumberBiomes",
"RangeElev",
"MeanSlope",
"BasinArea_sqkm",
"RangeW",
"PE_Median",
"Richness",
"RangeW_Corr")
for(i in 1:length(ScaleVar)) {
FocusCol <- grep(ScaleVar[i], names(PollenSub))
PollenSub[, FocusCol] <- scale(PollenSub[, FocusCol])
}
Elev <- glm(PollenSub$RangeElev ~ PollenSub$MedianResidence * PollenSub$NBiomes)
Elev <- glm(PollenSub$RangeElev ~ PollenSub$MedianResidence * PollenSub$NumberBiomes)
summary(Elev)
MedRes <- glm(PollenSub$MedianResidence ~ PollenSub$Elev * PollenSub$NumberBiomes)
MedRes <- glm(PollenSub$MedianResidence ~ PollenSub$RangeElev * PollenSub$NumberBiomes)
summary(MedRes)
plot(PollenSub$MedianResidence~PollenSub$NumberBiomes)
plot(PollenSub$MedianResidence~PollenSub$NumberBiomes, pch=16)
library(megaSDM)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
eval = FALSE
)
WD <- "C:/Users/bshipley6/Desktop/EXAMPLE"
knitr::opts_knit$set(root.dir = WD)
input_TA <- list.files(system.file("extdata", "trainingarea", package = "megaSDM"),
pattern = ".bil$",
full.names = TRUE)
envoutput <- "TestRun"
# Here we define the extent of the training and study regions in c(xmin, xmax, ymin, ymax) form.
TSEnv <- TrainStudyEnv(input_TA = input_TA,
output = envoutput,
clipTrain = c(-91.5, -75, 25.5, 36),
clipStudy = c(-91.5, -75, 25.5, 36))
Env2050_4.5 <- list.files(system.file("extdata", "predictenv/RCP4.5/2050", package = "megaSDM"),
pattern = ".bil$",
full.names = TRUE)
Env2070_4.5 <- list.files(system.file("extdata", "predictenv/RCP4.5/2070", package = "megaSDM"),
pattern = ".bil$",
full.names = TRUE)
Env4.5 <- list(Env2050_4.5, Env2070_4.5)
PredictEnv(studylayers = TSEnv$study,
futurelayers = Env4.5,
time_periods = c(2010, 2050, 2070),
output = envoutput,
scenario_name = "RCP4.5")
#Repeat with a different climate scenario (RCP8.5):
Env2050_8.5 <- list.files(system.file("extdata", "predictenv/RCP8.5/2050", package = "megaSDM"),
pattern = ".bil$",
full.names = TRUE)
Env2070_8.5 <- list.files(system.file("extdata", "predictenv/RCP8.5/2070", package = "megaSDM"),
pattern = ".bil$",
full.names = TRUE)
Env8.5 <- list(Env2050_8.5, Env2070_8.5)
PredictEnv(studylayers = TSEnv$study,
futurelayers = Env8.5,
time_periods = c(2010, 2050, 2070),
output = envoutput,
scenario_name = "RCP8.5")
# This function only takes occurrences from the described trainingarea extent.
# The defined extent should be the same (or similar to) as the extent of the training area.
# Given in latitude/longitude coordinates:
extent_occ <- c(-91.5, -75, 25.5, 36)
# A list of southeastern mammals for this example
spplist <- c("Puma concolor coryi",
"Podomys floridanus",
"Sylvilagus aquaticus",
"Sylvilagus palustris",
"Geomys pinetis",
"Neofiber alleni")
# Define the file folder where the occurrences will be written, within the working directory
# (if this folder doesn't already exist, megaSDM will make it)
occ_output <- "occurrences"
Occurrences <- OccurrenceCollection(spplist = spplist,
output = occ_output,
trainingarea = extent_occ)
??data.table
??data.table
?duplicated
?unique
??data.table
Occurrences <- OccurrenceCollection(spplist = spplist,
output = occ_output,
trainingarea = extent_occ)
occlist <- list.files(occ_output, pattern = ".csv", full.names = TRUE)
# In this example, we want to extract environmental data from each point (envextract = TRUE) using the environmental
# data we generated in the previous steps.
# We also want to environmentally subsample the data (envsample = TRUE), sing 25 bins for each environmental variable.
# Finally, we set the output to the same place as in the previous function so it will overwrite the original occurrence files.
OccurrenceManagement(occlist = occlist,
output = occ_output,
envextract = TRUE,
envsample = TRUE,
nbins = 25,
envdata = TSEnv$training)
library(megaSDM)
# Get the list of occurrence files again (even if they were written out in the same folder as before)
occlist <- list.files(occ_output, pattern = ".csv", full.names = TRUE)
# The location to print out the background buffers (.shp) (will be created if it doesn't exist)
buff_output <- "TestRun/buffers"
# Generates buffers for each species.
BackgroundBuffers(occlist = occlist,
envdata = TSEnv$training,
buff_output,
ncores = 2)
# Generates buffers for each species.
BackgroundBuffers(occlist = occlist,
envdata = TSEnv$training,
buff_output,
ncores = 2)
getwd()
install.packages("devtools")
install.packages(rtools40)
install.packages("devtools")
library(devtools)
library(devtools)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("testthat")
??raster
?raster
library(sp)
?sp
library(raster)
?raster
library(devtools)
install_github("brshipley/megaSDM", build_vignettes = TRUE)
vignette(megaSDM)
vignette("megaSDM")
vignette("megaSDM")
vignette(package = "megaSDM")
vignette("megaSDM", package = "megaSDM")
browseVignettes()
browseVignettes(package = "megaSDM")
browseVignettes(package = "raster")
browseVignettes(package = "megaSDM")
install_github("brshipley/megaSDM", build_vignettes = TRUE)
library(devtools)
library(roxygen2)
install.packages("Rcpp")
install_github("brshipley/megaSDM", build_vignettes = TRUE)
library(megaSDM)
??megaSDM
?megaSDM_vignette
??megaSDM_vignette
library(devtools)
library(roxygen2)
#When making changes to the script
setwd("C:/Users/bshipley6/Desktop/megaSDM/")
document()
load_all()
check()
?filename
